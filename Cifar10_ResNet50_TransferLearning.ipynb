{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10_ResNet50_TransferLearning.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, re, time, json\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import numpy as np\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LQZ3VPkOdrR",
        "outputId": "7eefcfe8-4beb-49fd-f595-8f246617e807"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ek2UzJj9O8-C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter\n",
        "  - Batch Size\n",
        "  - Define the class names"
      ],
      "metadata": {
        "id": "qIKBoFnAPAqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32 \n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "81ZxDlt5OfyH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(BATCH_SIZE)\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG1lddK_Paec",
        "outputId": "4d1a115b-df99-488a-85e6-e8d1101337df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ACoVzzaAOjGa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Preprocessing Data\n",
        "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset has 32 x 32 RGB images belonging to 10 classes. You will load the dataset from Keras.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b1v1HCTHQx2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(training_images, training_labels),(validation_images,validation_labels) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWNtQ1vQOjJj",
        "outputId": "1a790ff9-59ad-4fed-cd74-096b7c7fa486"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_images.shape,training_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKlB1C1zOjMZ",
        "outputId": "f78e33c6-f80c-438b-9234-1a258a8f3fec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation_images.shape,validation_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZM6HoJYOjOd",
        "outputId": "50c68d6c-fa14-442d-bb9f-da94b3aad197"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "svdPNTosOjRC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format input to correspond to the pretrained model."
      ],
      "metadata": {
        "id": "od_YKv-7R4Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_input(input_images):\n",
        "  input_images = input_images.astype(\"float32\")\n",
        "  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims"
      ],
      "metadata": {
        "id": "fH2Cp0XqRw3_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = preprocess_image_input(training_images)\n",
        "valid_x = preprocess_image_input(validation_images)"
      ],
      "metadata": {
        "id": "cHvplsobRw62"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0rZwQMbZRw9g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "obyCvy32OjTn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Developing the Model"
      ],
      "metadata": {
        "id": "Fs3j1HsQUoc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9XMsu9dqOjWT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0rNw8XNGA0PC"
      },
      "outputs": [],
      "source": [
        "# Define Feature Extractor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extractor(inputs):\n",
        "  feature_extractor_layer = tf.keras.applications.resnet.ResNet50(\n",
        "      input_shape = (224,224,3),\n",
        "      include_top = False, \n",
        "      weights = \"imagenet\")(inputs)\n",
        "\n",
        "  return feature_extractor_layer"
      ],
      "metadata": {
        "id": "9Fk12myFBHc6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define classifier\n",
        "def classifier(inputs):\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dense(1024, activation = \"relu\")(x)\n",
        "  x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
        "  x = tf.keras.layers.Dense(10, activation = \"softmax\", name = \"classification\")(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "poAXls5mBnI_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finalize model\n",
        "def final_model(inputs):\n",
        "  resize = tf.keras.layers.UpSampling2D(size = (7,7))(inputs)\n",
        "  resnet_feature_extractor = feature_extractor(resize)\n",
        "  classification_output = classifier(resnet_feature_extractor)\n",
        "  \n",
        "  return classification_output\n"
      ],
      "metadata": {
        "id": "HlreE_tPD6Ic"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define compile model\n",
        "def define_compile_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
        "  classification_output = final_model(inputs)\n",
        "  model = tf.keras.Model(inputs = inputs, outputs = classification_output)\n",
        "  model.compile(optimizer = \"SGD\",\n",
        "                loss = \"sparse_categorical_crossentropy\",\n",
        "                metrics = [\"accuracy\"])\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "o5g6bAJZExor"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_compile_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4ILQ2xiWU-3",
        "outputId": "e83f01e0-2204-4754-d914-26471572fae1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-zMyJGJWgPB",
        "outputId": "0033a5dd-c3e9-417f-bb5e-1cbb7ba60213"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 224, 224, 3)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " classification (Dense)      (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,215,818\n",
            "Trainable params: 26,162,698\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "32zErm2WWpw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 4\n",
        "history = model.fit(train_x,\n",
        "                    training_labels,\n",
        "                    epochs = EPOCHS,\n",
        "                    validation_data = (valid_x, validation_labels),\n",
        "                    batch_size = 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOCqE8N2Wthx",
        "outputId": "e8a6c613-3359-4ead-b746-4078c2746441"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "782/782 [==============================] - 271s 331ms/step - loss: 0.3973 - accuracy: 0.8702 - val_loss: 0.1942 - val_accuracy: 0.9303\n",
            "Epoch 2/4\n",
            "782/782 [==============================] - 257s 328ms/step - loss: 0.0988 - accuracy: 0.9677 - val_loss: 0.2000 - val_accuracy: 0.9323\n",
            "Epoch 3/4\n",
            "782/782 [==============================] - 257s 329ms/step - loss: 0.0319 - accuracy: 0.9910 - val_loss: 0.1826 - val_accuracy: 0.9446\n",
            "Epoch 4/4\n",
            "782/782 [==============================] - 257s 328ms/step - loss: 0.0129 - accuracy: 0.9971 - val_loss: 0.1616 - val_accuracy: 0.9532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CcdIR3mWXR_Y"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}